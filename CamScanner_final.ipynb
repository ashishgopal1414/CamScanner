{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/shirishgupta/Desktop/ComputerVision/\"\n",
    "image = cv2.imread(\"/Users/shirishgupta/Desktop/ComputerVision/sample_image2.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Use Gaussian Blurring combined with Adaptive Threshold** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_and_threshold(gray):\n",
    "    gray = cv2.GaussianBlur(gray,(3,3),2)\n",
    "    threshold = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "    threshold = cv2.fastNlMeansDenoising(threshold, 11, 31, 9)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Find the Biggest Contour** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: We made sure the minimum contour is bigger than 1/10 size of the whole picture. This helps in removing very small contours (noise) from our dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggest_contour(contours,min_area):\n",
    "    biggest = None\n",
    "    max_area = 0\n",
    "    biggest_n=0\n",
    "    approx_contour=None\n",
    "    for n,i in enumerate(contours):\n",
    "            area = cv2.contourArea(i)\n",
    "         \n",
    "            \n",
    "            if area > min_area/10:\n",
    "                    peri = cv2.arcLength(i,True)\n",
    "                    approx = cv2.approxPolyDP(i,0.02*peri,True)\n",
    "                    if area > max_area and len(approx)==4:\n",
    "                            biggest = approx\n",
    "                            max_area = area\n",
    "                            biggest_n=n\n",
    "                            approx_contour=approx\n",
    "                            \n",
    "                                                   \n",
    "    return biggest_n,approx_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    pts=pts.reshape(4,2)\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the exact (x,y) coordinates of the biggest contour and crop it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "   \n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Convert the image to grayscale**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Remove noise and smoothen out the image by applying blurring and thresholding techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Use Canny Edge Detection to find the edges**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Find the biggest contour and crop it out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation(image):\n",
    "  image=image.copy()  \n",
    "  height, width, channels = image.shape\n",
    "  gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "  image_size=gray.size\n",
    "  \n",
    "  threshold=blur_and_threshold(gray)\n",
    "  edges = cv2.Canny(threshold,50,150,apertureSize = 7)\n",
    "  contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  simplified_contours = []\n",
    "\n",
    "\n",
    "  for cnt in contours:\n",
    "      hull = cv2.convexHull(cnt)\n",
    "      simplified_contours.append(cv2.approxPolyDP(hull,\n",
    "                                0.001*cv2.arcLength(hull,True),True))\n",
    "  simplified_contours = np.array(simplified_contours)\n",
    "  biggest_n,approx_contour = biggest_contour(simplified_contours,image_size)\n",
    "\n",
    "  threshold = cv2.drawContours(image, simplified_contours ,biggest_n, (0,255,0), 1)\n",
    "\n",
    "  dst = 0\n",
    "  if approx_contour is not None and len(approx_contour)==4:\n",
    "      approx_contour=np.float32(approx_contour)\n",
    "      dst=four_point_transform(threshold,approx_contour)\n",
    "  croppedImage = dst\n",
    "  return croppedImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Increase the brightness of the image by playing with the \"V\" value (from HSV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_brightness(img, value=30):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sharpen the image using Kernel Sharpening Technique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_image(rotated):\n",
    "  # Create our shapening kernel, it must equal to one eventually\n",
    "  kernel_sharpening = np.array([[0,-1,0], \n",
    "                                [-1, 5,-1],\n",
    "                                [0,-1,0]])\n",
    "  # applying the sharpening kernel to the input image & displaying it.\n",
    "  sharpened = cv2.filter2D(rotated, -1, kernel_sharpening)\n",
    "  sharpened=increase_brightness(sharpened,30)  \n",
    "  return sharpened\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pass the image through the transformation function to crop out the biggest contour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Brighten & Sharpen the image to get a final cleaned image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_threshold = transformation(image)\n",
    "cleaned_image = final_image(blurred_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(path + \"Final_Image2.jpg\", cleaned_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
